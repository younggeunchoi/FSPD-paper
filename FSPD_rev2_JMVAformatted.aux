\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{model1-num-names}
\citation{Marcenko1967}
\citation{Bickel2008a,Bickel2008,Cai2010,Cai2011a,Cai2012c,Cai2012f,Rothman2009}
\citation{Bien2011,Lam2009}
\citation{Bickel2008,Rothman2009}
\citation{Bien2011,Lam2009,Liu2014,Rothman2012,Xue2012}
\citation{Rothman2012}
\citation{Xue2012}
\citation{Liu2014}
\Newlabel{SKT}{a}
\Newlabel{SNU}{b}
\Newlabel{UMBC}{c}
\Newlabel{mycorrespondingauthor}{1}
\Newlabel{myfootnote}{1}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\newlabel{sec:introduction}{{1}{1}{Introduction}{section.1}{}}
\citation{Lanckriet2002}
\citation{Jagannathan2003}
\newlabel{eqn:ideal-opt}{{1}{2}{Introduction}{equation.1.1}{}}
\newlabel{eqn:FSPD}{{2}{2}{Introduction}{equation.1.2}{}}
\citation{Rothman2009}
\citation{Cai2011b}
\citation{Bickel2008a}
\citation{Bickel2008}
\citation{Cai2010}
\citation{Rothman2012,Xue2012,Liu2014}
\@writefile{toc}{\contentsline {section}{\numberline {2}Covariance regularization and PDness}{3}{section.2}}
\newlabel{sec:previous}{{2}{3}{Covariance regularization and PDness}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Non-PDness of regularized covariance matrix estimators}{3}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Thresholding estimators}{3}{subsubsection.2.1.1}}
\newlabel{estimator:thr}{{3}{3}{Thresholding estimators}{equation.2.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Banding estimators}{3}{subsubsection.2.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Adding PDness to structural (sparse) regularization}{3}{subsection.2.2}}
\newlabel{subsec:optPD}{{2.2}{3}{Adding PDness to structural (sparse) regularization}{subsection.2.2}{}}
\citation{Rothman2012}
\citation{Xue2012}
\citation{Boyd2010}
\citation{Liu2014}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Miminum eigenvalues of regularized covariance matrix estimators ($n=100$, $p=400$). Left for thresholding estimators with threshold ($\lambda $) and right for banding estimators with varying bandwidth ($h$). The star ($*$)-marked point is the optimal threshold (bandwidth) selected by a five-fold cross-validation (CV). Note that all the CV-selected estimates are not PD.}}{4}{figure.1}}
\newlabel{figure:thresbanding}{{1}{4}{Miminum eigenvalues of regularized covariance matrix estimators ($n=100$, $p=400$). Left for thresholding estimators with threshold ($\lambda $) and right for banding estimators with varying bandwidth ($h$). The star ($*$)-marked point is the optimal threshold (bandwidth) selected by a five-fold cross-validation (CV). Note that all the CV-selected estimates are not PD}{figure.1}{}}
\newlabel{estimator:soft}{{4}{4}{Adding PDness to structural (sparse) regularization}{equation.2.4}{}}
\newlabel{estimator:logdet}{{5}{4}{Adding PDness to structural (sparse) regularization}{equation.2.5}{}}
\newlabel{estimator:EigCon}{{6}{4}{Adding PDness to structural (sparse) regularization}{equation.2.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Averaged empirical risks (estimation errors evaluated in matrix $\ell _1$, spectral, and Frobenius norms), frequency of positive definite estimates, and computing time (in seconds) for one fixed tuning parameter under 100 replications. Detailed settings of the simulation is given in Section \ref  {sec:simulation}. The data is generated under $n=100$, $p=400$, MV-$t$ distribution, and ${\bf  \Sigma }= {\bf  M}_1$ which is defined in Section \ref  {sec:simulation}. Computational convergence criteria is set as the relative error be smaller than $10^{-7}$. $\epsilon $ and $\tau $ are set as $10^{-2}$ for both the eigenvalue constraint method and the log-determinant barrier method.}}{5}{table.1}}
\newlabel{table:timecomp0}{{1}{5}{Averaged empirical risks (estimation errors evaluated in matrix $\ell _1$, spectral, and Frobenius norms), frequency of positive definite estimates, and computing time (in seconds) for one fixed tuning parameter under 100 replications. Detailed settings of the simulation is given in Section \ref {sec:simulation}. The data is generated under $n=100$, $p=400$, MV-$t$ distribution, and ${\bf \Sigma }= {\bf M}_1$ which is defined in Section \ref {sec:simulation}. Computational convergence criteria is set as the relative error be smaller than $10^{-7}$. $\epsilon $ and $\tau $ are set as $10^{-2}$ for both the eigenvalue constraint method and the log-determinant barrier method}{table.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}The linear shrinkage for fixed support positive definiteness (FSPD)}{5}{section.3}}
\newlabel{sec:FSPD}{{3}{5}{The linear shrinkage for fixed support positive definiteness (FSPD)}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Distance minimization}{5}{subsection.3.1}}
\newlabel{subsec:distance}{{3.1}{5}{Distance minimization}{subsection.3.1}{}}
\newlabel{objective:1}{{7}{5}{Distance minimization}{equation.3.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}The choice of $\alpha $}{6}{subsection.3.2}}
\newlabel{subsec:alpha}{{3.2}{6}{The choice of $\alpha $}{subsection.3.2}{}}
\newlabel{ineqn:alpha}{{8}{6}{The choice of $\alpha $}{equation.3.8}{}}
\newlabel{lemma:alpha}{{1}{6}{}{lemma.1}{}}
\newlabel{eqn:alpha}{{9}{6}{}{equation.3.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}The choice of $\mu $}{6}{subsection.3.3}}
\newlabel{subsec:mu}{{3.3}{6}{The choice of $\mu $}{subsection.3.3}{}}
\newlabel{objective:2}{{10}{6}{The choice of $\mu $}{equation.3.10}{}}
\newlabel{lemma:muspect}{{2}{6}{Spectral norm}{lemma.2}{}}
\citation{Cai2014b}
\newlabel{lemma:mufrob}{{3}{7}{Scaled Frobenius norm}{lemma.3}{}}
\newlabel{eqn:lemma3-1}{{11}{7}{Scaled Frobenius norm}{equation.3.11}{}}
\newlabel{eqn:mufrob1}{{12}{7}{Scaled Frobenius norm}{equation.3.12}{}}
\newlabel{thm:FSPDsumm}{{1}{7}{Distance between the initial and FSPD estimators}{theorem.1}{}}
\citation{Xue2012}
\citation{Cai2010}
\citation{Cai2012c}
\citation{Cai2012f}
\citation{Cai2011b}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Statistical properties of the FSPD estimator}{8}{subsection.3.4}}
\newlabel{subsec:convrate}{{3.4}{8}{Statistical properties of the FSPD estimator}{subsection.3.4}{}}
\newlabel{eqn:triangle_inequality}{{13}{8}{Statistical properties of the FSPD estimator}{equation.3.13}{}}
\newlabel{prop:FSPDcov1}{{2}{8}{}{theorem.2}{}}
\newlabel{epsbound}{{14}{8}{Statistical properties of the FSPD estimator}{equation.3.14}{}}
\citation{Rothman2012,Xue2012,Liu2014}
\citation{Demmel1997}
\citation{Golub2012}
\citation{Lehoucq1996}
\citation{Sorensen1990}
\citation{Golub2002}
\newlabel{prop:FSPDcov2}{{3}{9}{}{theorem.3}{}}
\newlabel{eqn:theorem3-1}{{15}{9}{Statistical properties of the FSPD estimator}{equation.3.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Computation}{9}{subsection.3.5}}
\newlabel{subsec:computation}{{3.5}{9}{Computation}{subsection.3.5}{}}
\citation{Rothman2012}
\citation{Xue2012}
\citation{Xue2012}
\citation{Xue2012}
\citation{Xue2012}
\@writefile{toc}{\contentsline {section}{\numberline {4}Simulation study}{10}{section.4}}
\newlabel{sec:simulation}{{4}{10}{Simulation study}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Empirical risk}{10}{subsection.4.1}}
\newlabel{subsec:emperrcomp}{{4.1}{10}{Empirical risk}{subsection.4.1}{}}
\citation{Rothman2012}
\citation{Rothman2012}
\citation{Xue2012}
\citation{Xue2012}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Non-PDness of the soft thresholding estimator. The columns give the minimum eigenvalue (Min. eig), the proportion of negative eigenvalues (\#(Neg. eig.)/$p$), and the number of cases that the estimates are PD (\#(PD)) over 100 replications. Corresponding standard errors are presented in parenthesis.}}{11}{table.2}}
\newlabel{table:softspectrum}{{2}{11}{Non-PDness of the soft thresholding estimator. The columns give the minimum eigenvalue (Min. eig), the proportion of negative eigenvalues (\#(Neg. eig.)/$p$), and the number of cases that the estimates are PD (\#(PD)) over 100 replications. Corresponding standard errors are presented in parenthesis}{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Computation time}{11}{subsection.4.2}}
\newlabel{subsec:timecomp}{{4.2}{11}{Computation time}{subsection.4.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces  Empirical risks (estimation errors evaluated in matrix $\ell _1$, spectral, and Frobenius norms) of the PD covariance matrix esimators and soft thresholding estimator based on 100 replications. Standard errors are presented in parenthesis.}}{12}{table.3}}
\newlabel{table:emperrcomp}{{3}{12}{Empirical risks (estimation errors evaluated in matrix $\ell _1$, spectral, and Frobenius norms) of the PD covariance matrix esimators and soft thresholding estimator based on 100 replications. Standard errors are presented in parenthesis}{table.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Computation time (in seconds) of the four PD estimators and the soft thresholding estimator.}}{12}{table.4}}
\newlabel{table:timecomp}{{4}{12}{Computation time (in seconds) of the four PD estimators and the soft thresholding estimator}{table.4}{}}
\citation{Tsanas2014}
\citation{Won2013}
\citation{Lanckriet2002}
\citation{Lanckriet2002}
\citation{Tsanas2014}
\citation{Rothman2012}
\citation{Rothman2012}
\citation{Rothman2012}
\citation{Little2009}
\citation{Tsanas2014}
\citation{Tsanas2014}
\citation{Ledoit2004}
\citation{Won2013}
\citation{Xue2012}
\citation{Cai2011b}
\citation{Cai2011b}
\citation{Cai2011b}
\citation{Xue2012}
\@writefile{toc}{\contentsline {section}{\numberline {5}Two applications}{13}{section.5}}
\newlabel{sec:plug-in}{{5}{13}{Two applications}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Linear minimax classifier applied to speech recognition}{13}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Linear minimax probability machine}{13}{subsubsection.5.1.1}}
\newlabel{eqn:linearMPM}{{16}{13}{Linear minimax probability machine}{equation.5.16}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Example: Speech recognition}{13}{subsubsection.5.1.2}}
\newlabel{subsubSection:speech}{{5.1.2}{13}{Example: Speech recognition}{subsubsection.5.1.2}{}}
\citation{Tsanas2014}
\citation{Sun2010}
\citation{Chan1999}
\citation{Jagannathan2003}
\citation{Chan1999}
\citation{Jagannathan2003}
\citation{Jagannathan2003}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces The average classification accuracies (standard deviations in parenthesis) for the LMPM with selected PD covariance matrix estimators based on 100 random partitions. The abbreviations of the estimators are introduced in the main body of the Section.}}{14}{table.5}}
\newlabel{table:linearMPM}{{5}{14}{The average classification accuracies (standard deviations in parenthesis) for the LMPM with selected PD covariance matrix estimators based on 100 random partitions. The abbreviations of the estimators are introduced in the main body of the Section}{table.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Markowitz portfolio optimization}{14}{subsection.5.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Minimum-variance portfolio allocation and short-sale}{14}{subsubsection.5.2.1}}
\newlabel{eqn:minvar}{{17}{14}{Minimum-variance portfolio allocation and short-sale}{equation.5.17}{}}
\newlabel{eqn:minvarnoshort}{{18}{14}{Minimum-variance portfolio allocation and short-sale}{equation.5.18}{}}
\citation{Jagannathan2003}
\citation{Fan2013}
\citation{Fan2013}
\citation{Xue2012}
\citation{Won2013}
\citation{Jagannathan2003}
\citation{Won2013}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Example: Dow Jones stock return}{15}{subsubsection.5.2.2}}
\citation{Cai2011}
\citation{Meinshausen2006}
\citation{Peng2009}
\citation{Friedman2010}
\citation{Khare2015}
\citation{Mazumder2012}
\citation{Friedman2008}
\citation{Witten2011}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Empirical out-of-sample performances, from 30 constituents of DJIA with 60 days of holding, starting from 2/18/1994. All the rates are annualized.}}{16}{table.6}}
\newlabel{table:portfolio}{{6}{16}{Empirical out-of-sample performances, from 30 constituents of DJIA with 60 days of holding, starting from 2/18/1994. All the rates are annualized}{table.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Estimation of positive definite precision matrices}{16}{section.6}}
\newlabel{sec:prec}{{6}{16}{Estimation of positive definite precision matrices}{section.6}{}}
\newlabel{thm:FSPDprec}{{4}{16}{}{theorem.4}{}}
\citation{Kwon2016}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Spectral information of selected sparse precision matrix estimators when the true precision matrix is ${\bf  M}_1$ (tapered Toeplitz matrix).}}{17}{table.7}}
\newlabel{table:precspectrum}{{6}{17}{Estimation of positive definite precision matrices}{table.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Concluding remarks}{17}{section.7}}
\newlabel{sec:concluding}{{7}{17}{Concluding remarks}{section.7}{}}
\citation{Won2013}
\bibcite{Bai2010}{{1}{2010}{{Bai and Silverstein}}{{}}}
\bibcite{Bickel2008a}{{2}{2008a}{{Bickel and Levina}}{{}}}
\bibcite{Bickel2008}{{3}{2008b}{{Bickel and Levina}}{{}}}
\bibcite{Bien2011}{{4}{2011}{{Bien and Tibshirani}}{{}}}
\bibcite{Boyd2010}{{5}{2010}{{Boyd et~al.}}{{}}}
\bibcite{Cai2011b}{{6}{2011}{{Cai and Liu}}{{}}}
\bibcite{Cai2011}{{7}{2011}{{Cai et~al.}}{{}}}
\bibcite{Cai2011a}{{8}{2015}{{Cai and Low}}{{}}}
\bibcite{Cai2014b}{{9}{2016}{{Cai et~al.}}{{}}}
\bibcite{Cai2012c}{{10}{2012}{{Cai and Yuan}}{{}}}
\bibcite{Cai2010}{{11}{2010}{{Cai et~al.}}{{}}}
\bibcite{Cai2012f}{{12}{2012}{{Cai and Zhou}}{{}}}
\bibcite{Chan1999}{{13}{1999}{{Chan}}{{}}}
\bibcite{Demmel1997}{{14}{1997}{{Demmel}}{{}}}
\bibcite{Fan2013}{{15}{2013}{{Fan et~al.}}{{}}}
\bibcite{Friedman2008}{{16}{2008}{{Friedman et~al.}}{{}}}
\bibcite{Friedman2010}{{17}{2010}{{Friedman et~al.}}{{}}}
\bibcite{Golub2012}{{18}{2012}{{Golub and {Van Loan}}}{{}}}
\bibcite{Golub2002}{{19}{2002}{{Golub and Ye}}{{}}}
\bibcite{Green1992}{{20}{1992}{{Green and Hollifield}}{{}}}
\bibcite{Jagannathan2003}{{21}{2003}{{Jagannathan and Ma}}{{}}}
\bibcite{Khare2015}{{22}{2015}{{Khare et~al.}}{{}}}
\bibcite{Kwon2016}{{23}{2017}{{Kwon et~al.}}{{}}}
\bibcite{Lam2009}{{24}{2009}{{Lam and Fan}}{{}}}
\bibcite{Lanckriet2002}{{25}{2002}{{Lanckriet et~al.}}{{}}}
\bibcite{Ledoit2004}{{26}{2004}{{Ledoit and Wolf}}{{}}}
\bibcite{Lehoucq1996}{{27}{1996}{{Lehoucq and Sorensen}}{{}}}
\bibcite{Little2009}{{28}{2009}{{Little et~al.}}{{}}}
\bibcite{Liu2014}{{29}{2014}{{Liu et~al.}}{{}}}
\bibcite{Luenberger2013}{{30}{2013}{{Luenberger}}{{}}}
\bibcite{Marcenko1967}{{31}{1967}{{Marcenko and Pastur}}{{}}}
\bibcite{Markowitz1952}{{32}{1952}{{Markowitz}}{{}}}
\bibcite{Mazumder2012}{{33}{2012}{{Mazumder and Hastie}}{{}}}
\bibcite{Meinshausen2006}{{34}{2006}{{Meinshausen and B\"{u}hlmann}}{{}}}
\bibcite{Merton1980}{{35}{1980}{{Merton}}{{}}}
\bibcite{Peng2009}{{36}{2009}{{Peng et~al.}}{{}}}
\bibcite{Rothman2012}{{37}{2012}{{Rothman}}{{}}}
\bibcite{Rothman2009}{{38}{2009}{{Rothman et~al.}}{{}}}
\bibcite{Sorensen1990}{{39}{1990}{{Sorensen}}{{}}}
\bibcite{Stein1956}{{40}{1956}{{Stein}}{{}}}
\bibcite{Sun2010}{{41}{2010}{{Sun et~al.}}{{}}}
\bibcite{Tsanas2014}{{42}{2014}{{Tsanas et~al.}}{{}}}
\bibcite{Witten2011}{{43}{2011}{{Witten et~al.}}{{}}}
\bibcite{Won2013}{{44}{2013}{{Won et~al.}}{{}}}
\bibcite{Xue2012}{{45}{2012}{{Xue et~al.}}{{}}}
