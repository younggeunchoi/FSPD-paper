\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{model1-num-names}
\citation{Marcenko1967}
\citation{Bickel2008a,Bickel2008,Cai2010,Cai2011a,Cai2012c,Cai2012f,Rothman2009}
\citation{Bien2011,Lam2009}
\citation{Bickel2008,Rothman2009}
\citation{Bien2011,Lam2009,Liu2014,Rothman2012,Xue2012}
\citation{Rothman2012}
\citation{Xue2012}
\citation{Liu2014}
\Newlabel{SKT}{a}
\Newlabel{SNU}{b}
\Newlabel{UMBC}{c}
\Newlabel{mycorrespondingauthor}{1}
\Newlabel{myfootnote}{1}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\newlabel{sec:introduction}{{1}{1}{Introduction}{section.1}{}}
\citation{Lanckriet2002}
\citation{Jagannathan2003}
\newlabel{eqn:ideal-opt}{{1}{2}{Introduction}{equation.1.1}{}}
\newlabel{eqn:FSPD}{{2}{2}{Introduction}{equation.1.2}{}}
\citation{Rothman2009}
\citation{Cai2011b}
\citation{Bickel2008a}
\citation{Bickel2008}
\citation{Cai2010}
\citation{Rothman2012,Xue2012,Liu2014}
\citation{Rothman2012}
\@writefile{toc}{\contentsline {section}{\numberline {2}Covariance regularization and PDness}{3}{section.2}}
\newlabel{sec:previous}{{2}{3}{Covariance regularization and PDness}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Non-PDness of regularized covariance matrix estimators}{3}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Thresholding estimators}{3}{subsubsection.2.1.1}}
\newlabel{estimator:thr}{{3}{3}{Thresholding estimators}{equation.2.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Banding estimators}{3}{subsubsection.2.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Adding PDness to structural (sparse) regularization}{3}{subsection.2.2}}
\newlabel{subsec:optPD}{{2.2}{3}{Adding PDness to structural (sparse) regularization}{subsection.2.2}{}}
\newlabel{estimator:soft}{{4}{3}{Adding PDness to structural (sparse) regularization}{equation.2.4}{}}
\citation{Xue2012}
\citation{Boyd2010}
\citation{Liu2014}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Miminum eigenvalues of regularized covariance matrix estimators ($n=100$, $p=400$). Left for thresholding estimators with threshold ($\lambda $) and right for banding estimators with varying bandwidth ($h$). The star ($*$)-marked point is the optimal threshold (bandwidth) selected by a five-fold cross-validation (CV). Note that all the CV-selected estimates are not PD.}}{4}{figure.1}}
\newlabel{figure:thresbanding}{{1}{4}{Miminum eigenvalues of regularized covariance matrix estimators ($n=100$, $p=400$). Left for thresholding estimators with threshold ($\lambda $) and right for banding estimators with varying bandwidth ($h$). The star ($*$)-marked point is the optimal threshold (bandwidth) selected by a five-fold cross-validation (CV). Note that all the CV-selected estimates are not PD}{figure.1}{}}
\newlabel{estimator:logdet}{{5}{4}{Adding PDness to structural (sparse) regularization}{equation.2.5}{}}
\newlabel{estimator:EigCon}{{6}{4}{Adding PDness to structural (sparse) regularization}{equation.2.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Averaged empirical risks (estimation errors evaluated in matrix $\ell _1$, spectral, and Frobenius norms), frequency of positive definite estimates, and computing time (in seconds), for one fixed tuning parameter under 100 replications from the same simulation settings as that used in Figure \ref  {figure:thresbanding}. Computational convergence criteria is set as the relative error be smaller than $10^{-7}$. $\epsilon $ and $\tau $ are set as $10^{-2}$ for both the eigenvalue constraint method and the log-determinant barrier method.}}{5}{table.1}}
\newlabel{table:timecomp0}{{1}{5}{Averaged empirical risks (estimation errors evaluated in matrix $\ell _1$, spectral, and Frobenius norms), frequency of positive definite estimates, and computing time (in seconds), for one fixed tuning parameter under 100 replications from the same simulation settings as that used in Figure \ref {figure:thresbanding}. Computational convergence criteria is set as the relative error be smaller than $10^{-7}$. $\epsilon $ and $\tau $ are set as $10^{-2}$ for both the eigenvalue constraint method and the log-determinant barrier method}{table.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}The linear shrinkage for fixed support positive definiteness (FSPD)}{5}{section.3}}
\newlabel{sec:FSPD}{{3}{5}{The linear shrinkage for fixed support positive definiteness (FSPD)}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Distance minimization}{5}{subsection.3.1}}
\newlabel{subsec:distance}{{3.1}{5}{Distance minimization}{subsection.3.1}{}}
\newlabel{objective:1}{{7}{5}{Distance minimization}{equation.3.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}The choice of $\alpha $}{6}{subsection.3.2}}
\newlabel{subsec:alpha}{{3.2}{6}{The choice of $\alpha $}{subsection.3.2}{}}
\newlabel{ineqn:alpha}{{8}{6}{The choice of $\alpha $}{equation.3.8}{}}
\newlabel{lemma:alpha}{{1}{6}{}{lemma.1}{}}
\newlabel{eqn:alpha}{{9}{6}{}{equation.3.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}The choice of $\mu $}{6}{subsection.3.3}}
\newlabel{subsec:mu}{{3.3}{6}{The choice of $\mu $}{subsection.3.3}{}}
\newlabel{objective:2}{{10}{6}{The choice of $\mu $}{equation.3.10}{}}
\newlabel{lemma:muspect}{{2}{6}{Spectral norm}{lemma.2}{}}
\newlabel{lemma:mufrob}{{3}{6}{Scaled Frobenius norm}{lemma.3}{}}
\newlabel{eqn:lemma3-1}{{11}{6}{Scaled Frobenius norm}{equation.3.11}{}}
\citation{Cai2016a}
\newlabel{eqn:mufrob1}{{12}{7}{Scaled Frobenius norm}{equation.3.12}{}}
\newlabel{thm:FSPDsumm}{{1}{7}{Distance between the initial and FSPD estimators}{theorem.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Statistical properties of the FSPD estimator}{7}{subsection.3.4}}
\newlabel{subsec:convrate}{{3.4}{7}{Statistical properties of the FSPD estimator}{subsection.3.4}{}}
\newlabel{eqn:triangle_inequality}{{13}{7}{Statistical properties of the FSPD estimator}{equation.3.13}{}}
\citation{Xue2012}
\citation{Cai2010}
\citation{Cai2012c}
\citation{Cai2012f}
\citation{Cai2011b}
\newlabel{prop:FSPDcov1}{{2}{8}{}{theorem.2}{}}
\newlabel{epsbound}{{14}{8}{Statistical properties of the FSPD estimator}{equation.3.14}{}}
\newlabel{prop:FSPDcov2}{{3}{8}{}{theorem.3}{}}
\citation{Rothman2012,Xue2012,Liu2014}
\citation{Demmel1997}
\citation{Golub2012}
\citation{Lehoucq1996}
\citation{Sorensen1990}
\citation{Golub2002}
\newlabel{eqn:theorem3-1}{{15}{9}{Statistical properties of the FSPD estimator}{equation.3.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Computation}{9}{subsection.3.5}}
\newlabel{subsec:computation}{{3.5}{9}{Computation}{subsection.3.5}{}}
\citation{Rothman2012}
\citation{Xue2012}
\citation{Xue2012}
\citation{Xue2012}
\@writefile{toc}{\contentsline {section}{\numberline {4}Simulation study}{10}{section.4}}
\newlabel{sec:simulation}{{4}{10}{Simulation study}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Empirical risk}{10}{subsection.4.1}}
\newlabel{subsec:emperrcomp}{{4.1}{10}{Empirical risk}{subsection.4.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Non-PDness of the soft thresholding estimator. The columns give the minimum eigenvalue (Min. eig), the proportion of negative eigenvalues (\#(Neg. eig.)/$p$), and the number of cases that the estimates are PD (\#(PD)) over 100 replications. Corresponding standard errors are presented in parenthesis.}}{10}{table.2}}
\newlabel{table:softspectrum}{{2}{10}{Non-PDness of the soft thresholding estimator. The columns give the minimum eigenvalue (Min. eig), the proportion of negative eigenvalues (\#(Neg. eig.)/$p$), and the number of cases that the estimates are PD (\#(PD)) over 100 replications. Corresponding standard errors are presented in parenthesis}{table.2}{}}
\citation{Xue2012}
\citation{Rothman2012}
\citation{Rothman2012}
\citation{Xue2012}
\citation{Xue2012}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Computation time}{11}{subsection.4.2}}
\newlabel{subsec:timecomp}{{4.2}{11}{Computation time}{subsection.4.2}{}}
\citation{Tsanas2014}
\citation{Won2013}
\citation{Lanckriet2002}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces  Empirical risks (estimation errors evaluated in matrix $\ell _1$, spectral, and Frobenius norms) of the PD covariance matrix esimators and soft thresholding estimator based on 100 replications. Standard errors are presented in parenthesis.}}{12}{table.3}}
\newlabel{table:emperrcomp}{{3}{12}{Empirical risks (estimation errors evaluated in matrix $\ell _1$, spectral, and Frobenius norms) of the PD covariance matrix esimators and soft thresholding estimator based on 100 replications. Standard errors are presented in parenthesis}{table.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Computation time (in seconds) of the four PD estimators and the soft thresholding estimator.}}{12}{table.4}}
\newlabel{table:timecomp}{{4}{12}{Computation time (in seconds) of the four PD estimators and the soft thresholding estimator}{table.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Two applications}{12}{section.5}}
\newlabel{sec:plug-in}{{5}{12}{Two applications}{section.5}{}}
\citation{Lanckriet2002}
\citation{Tsanas2014}
\citation{Rothman2012}
\citation{Rothman2012}
\citation{Rothman2012}
\citation{Little2009}
\citation{Tsanas2014}
\citation{Tsanas2014}
\citation{Ledoit2004}
\citation{Won2013}
\citation{Xue2012}
\citation{Cai2011b}
\citation{Cai2011b}
\citation{Cai2011b}
\citation{Xue2012}
\citation{Tsanas2014}
\citation{Sun2010}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Linear minimax classifier applied to speech recognition}{13}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Linear minimax probability machine}{13}{subsubsection.5.1.1}}
\newlabel{eqn:linearMPM}{{16}{13}{Linear minimax probability machine}{equation.5.16}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Example: Speech recognition}{13}{subsubsection.5.1.2}}
\newlabel{subsubSection:speech}{{5.1.2}{13}{Example: Speech recognition}{subsubsection.5.1.2}{}}
\citation{Chan1999}
\citation{Jagannathan2003}
\citation{Chan1999}
\citation{Jagannathan2003}
\citation{Jagannathan2003}
\citation{Jagannathan2003}
\citation{Fan2013}
\citation{Fan2013}
\citation{Xue2012}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces The average classification accuracies (standard deviations in parenthesis) for the LMPM with selected PD covariance matrix estimators based on 100 random partitions. The abbreviations of the estimators are introduced in the main body of the Section.}}{14}{table.5}}
\newlabel{table:linearMPM}{{5}{14}{The average classification accuracies (standard deviations in parenthesis) for the LMPM with selected PD covariance matrix estimators based on 100 random partitions. The abbreviations of the estimators are introduced in the main body of the Section}{table.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Markowitz portfolio optimization}{14}{subsection.5.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Minimum-variance portfolio allocation and short-sale}{14}{subsubsection.5.2.1}}
\newlabel{eqn:minvar}{{17}{14}{Minimum-variance portfolio allocation and short-sale}{equation.5.17}{}}
\newlabel{eqn:minvarnoshort}{{18}{14}{Minimum-variance portfolio allocation and short-sale}{equation.5.18}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Example: Dow Jones stock return}{14}{subsubsection.5.2.2}}
\citation{Won2013}
\citation{Jagannathan2003}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Empirical out-of-sample performances, from 30 constituents of DJIA with 60 days of holding, starting from 2/18/1994. All the rates are annualized.}}{15}{table.6}}
\newlabel{table:portfolio}{{6}{15}{Empirical out-of-sample performances, from 30 constituents of DJIA with 60 days of holding, starting from 2/18/1994. All the rates are annualized}{table.6}{}}
\citation{Won2013}
\citation{Cai2011}
\citation{Meinshausen2006}
\citation{Peng2009}
\citation{Friedman2010}
\citation{Khare2015}
\citation{Mazumder2012}
\citation{Friedman2008}
\citation{Witten2011}
\citation{Khare2015}
\citation{Friedman2010}
\citation{Kwon2016}
\@writefile{toc}{\contentsline {section}{\numberline {6}Estimation of positive definite precision matrices}{16}{section.6}}
\newlabel{sec:prec}{{6}{16}{Estimation of positive definite precision matrices}{section.6}{}}
\newlabel{thm:FSPDprec}{{4}{16}{}{theorem.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Concluding remarks}{16}{section.7}}
\newlabel{sec:concluding}{{7}{16}{Concluding remarks}{section.7}{}}
\citation{Won2013}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Spectral information of selected sparse precision matrix estimators when the true precision matrix is ${\bf  M}_1$ (tapered Toeplitz matrix).}}{17}{table.7}}
\newlabel{table:precspectrum}{{6}{17}{Estimation of positive definite precision matrices}{table.7}{}}
\bibcite{Bickel2008a}{{1}{2008{}}{{Bickel and Levina}}{{}}}
\bibcite{Bickel2008}{{2}{2008{}}{{Bickel and Levina}}{{}}}
\bibcite{Bien2011}{{3}{2011}{{Bien and Tibshirani}}{{}}}
\bibcite{Boyd2010}{{4}{2010}{{Boyd et~al.}}{{Boyd, Parikh, Chu, Peleato, and Eckstein}}}
\bibcite{Cai2011b}{{5}{2011}{{Cai and Liu}}{{}}}
\bibcite{Cai2011}{{6}{2011}{{Cai et~al.}}{{Cai, Liu, and Luo}}}
\bibcite{Cai2011a}{{7}{2015}{{Cai and Low}}{{}}}
\bibcite{Cai2016a}{{8}{2016}{{Cai et~al.}}{{Cai, Ren, and Zhou}}}
\bibcite{Cai2012c}{{9}{2012}{{Cai and Yuan}}{{}}}
\bibcite{Cai2010}{{10}{2010}{{Cai et~al.}}{{Cai, Zhang, and Zhou}}}
\bibcite{Cai2012f}{{11}{2012}{{Cai and Zhou}}{{}}}
\bibcite{Chan1999}{{12}{1999}{{Chan}}{{}}}
\bibcite{Demmel1997}{{13}{1997}{{Demmel}}{{}}}
\bibcite{Fan2013}{{14}{2013}{{Fan et~al.}}{{Fan, Liao, and Mincheva}}}
\bibcite{Friedman2008}{{15}{2008}{{Friedman et~al.}}{{Friedman, Hastie, and Tibshirani}}}
\bibcite{Friedman2010}{{16}{2010}{{Friedman et~al.}}{{Friedman, Hastie, and Tibshirani}}}
\bibcite{Golub2002}{{17}{2002}{{Golub and Ye}}{{}}}
\bibcite{Golub2012}{{18}{2012}{{Golub and {Van Loan}}}{{}}}
\bibcite{Jagannathan2003}{{19}{2003}{{Jagannathan and Ma}}{{}}}
\bibcite{Khare2015}{{20}{2015}{{Khare et~al.}}{{Khare, Oh, and Rajaratnam}}}
\bibcite{Kwon2016}{{21}{2017}{{Kwon et~al.}}{{Kwon, Choi, Park, Ziegler, and Paik}}}
\bibcite{Lam2009}{{22}{2009}{{Lam and Fan}}{{}}}
\bibcite{Lanckriet2002}{{23}{2002}{{Lanckriet et~al.}}{{Lanckriet, {El Ghaoui}, Bhattacharyya, and Jordan}}}
\bibcite{Ledoit2004}{{24}{2004}{{Ledoit and Wolf}}{{}}}
\bibcite{Lehoucq1996}{{25}{1996}{{Lehoucq and Sorensen}}{{}}}
\bibcite{Little2009}{{26}{2009}{{Little et~al.}}{{Little, McSharry, Hunter, Spielman, and Ramig}}}
\bibcite{Liu2014}{{27}{2014}{{Liu et~al.}}{{Liu, Wang, and Zhao}}}
\bibcite{Marcenko1967}{{28}{1967}{{Marcenko and Pastur}}{{}}}
\bibcite{Mazumder2012}{{29}{2012}{{Mazumder and Hastie}}{{}}}
\bibcite{Meinshausen2006}{{30}{2006}{{Meinshausen and B{\"{u}}hlmann}}{{}}}
\bibcite{Peng2009}{{31}{2009}{{Peng et~al.}}{{Peng, Wang, Zhou, and Zhu}}}
\bibcite{Rothman2012}{{32}{2012}{{Rothman}}{{}}}
\bibcite{Rothman2009}{{33}{2009}{{Rothman et~al.}}{{Rothman, Levina, and Zhu}}}
\bibcite{Sorensen1990}{{34}{1990}{{Sorensen}}{{}}}
\bibcite{Sun2010}{{35}{2010}{{Sun et~al.}}{{Sun, Todorovic, and Goodison}}}
\bibcite{Tsanas2014}{{36}{2014}{{Tsanas et~al.}}{{Tsanas, Little, Fox, and Ramig}}}
\bibcite{Witten2011}{{37}{2011}{{Witten et~al.}}{{Witten, Friedman, and Simon}}}
\bibcite{Won2013}{{38}{2013}{{Won et~al.}}{{Won, Lim, Kim, and Rajaratnam}}}
\bibcite{Xue2012}{{39}{2012}{{Xue et~al.}}{{Xue, Ma, and Zou}}}
